<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Zhiqiang Yan</title>

  <meta name="author" content="Zhiqiang Yan">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/cmu-seal-r.png">
</head>

<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p style="text-align:center">
                    <name>Zhiqiang Yan</name>
                  </p>
                  <!-- <p>I am a CS undergraudate at <a href="http://english.pku.edu.cn/">Peking University</a> starting from Sep. 2016. For now I'm applying for graduate school in Computer Science.
              </p> -->
                  <p>I am a Phd student at <a href="http://www.patternrecognition.asia/">PCALab</a> of <a
                      href="https://www.njust.edu.cn/">Nanjing University of Science and Technology</a> (NJUST), advised by 
			  <a
                      href="http://202.119.85.163/open/TutorInfo.aspx?dsbh=tLbjVM9T1OzsoNduSpyHQg==&yxsh=4iVdgPyuKTE=&zydm=L-3Jh59wXco=">Jian Yang</a> 
			  and co-advised by
                    <a href="https://sites.google.com/view/junlineu/">Jun Li. </a>
                  </p>
                  <!-- <p>
                I am a research intern at IV-OCR Group, <a href="https://www.sensetime.com/en/">Sensetime AI</a>, starting from Oct. 2019. At Sensetime, I've worked on Form Structuralization and Image Steganography.
              </p> -->
                  <!-- <p>
                I spent last summer as an intern at the <a href="https://www.ri.cmu.edu/">Robotics Institute</a> of <a href="https://www.cmu.edu/">Carnegie Mellon University</a>, where I'm fortunate to be advised by <a href="http://www.cs.cmu.edu/~aayushb/">Aayush Bansal</a> and <a href="https://www.cs.cmu.edu/~deva/">Deva Ramanan</a>.
              </p> -->
                  <p>I obtained my M.S degree in 2018 from NJUST.
                  <p style="text-align:center">
                    <a href="mailto:yanzq@njust.edu.cn"> Email </a> &nbsp/&nbsp
                    <!--                 <a href="data/Kangle_CV.pdf">CV</a> &nbsp/&nbsp -->
                    <a href="https://github.com/yanzq95"> GitHub </a> &nbsp/&nbsp
                    <a href="https://scholar.google.com/citations?user=hnrkzIEAAAAJ&hl=zh-CN&oi=sra"> Google Scholar </a> &nbsp/&nbsp
					<a href="images/wechat_yanzq.jpg"> WeChat </a> 
                  </p>
                </td>
                <td style="padding:2.5%;width:40%;max-width:40%">
                  <a><img style="width:200px;max-width:100%" alt="profile photo" src="images/yanzq.png" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Research</heading>
                  <p>
                    <!--                 I'm interested in Multimodal Perception, including Computer Vison and Audio Processing. I'm also interested in applications of Information Theory to Maching Learning.  -->

                    <!--                 So far, my research mainly involves computer-aided creation. My research proposal of <em>'Reconstructing and Synthesizing 3D-Aware Content'</em> won 2022 Microsoft Research PhD Fellowship.  -->
                    My research interests include computer vision and machine learning, especially on depth estimation, depth completion, and depth super-resolution. These tasks are crucial for various applications, such as self-driving, robotic vision, and related 3D visual perception.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
		  
		  
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

              <tr onmouseout="nsdnet_stop()" onmouseover="nsdnet_start()"> <!-- bgcolor="#ffffd0" -->
                <td style="padding:20px;width:25%;vertical-align:middle">
                    <img src="images/NSDNet/demo.gif" width="300">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">

                  <papertitle><a href="https://arxiv.org/pdf/2303.04940v4.pdf">Non-aligned supervision for Real Image Dehazing</a>
                  </papertitle>
                  <br>
                  <strong>Zhiqiang Yan</strong>, 
				  <a href="https://scholar.google.com/citations?hl=zh-CN&user=0wale0IAAAAJ">Fei Guo</a>, 
				  <a href="http://www.patternrecognition.asia/qian/">Jianjun Qian</a>, 
				  <a href="http://implus.github.io/">Xiang Li</a>, 
				  <a href="https://sites.google.com/view/junlineu/">Jun Li*</a>, 
				  <a href="http://202.119.85.163/open/TutorInfo.aspx?dsbh=tLbjVM9T1OzsoNduSpyHQg==&yxsh=4iVdgPyuKTE=&zydm=L-3Jh59wXco=">Jian Yang*</a>
                  <br> <br>
                  <em>arXiv</em>, 2023
                  <br>
                  <a href="projectpage/NSDNet/index.html">project page</a> / 
				  <a href="https://github.com/fanjunkai1/NSDNet">github</a>
                  <p></p>
                  <p>Given an image or video captured in a real foggy scene, our 
				  model is capable of restoring the corresponding clear scene image or video. Moreover, training our model does not require fully aligned ground truth (GT), which helps us collect real foggy scene data.</p>
                </td>
              </tr>

            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Selected Honors and Awards</heading>
                  <ul>
                    <li>2018, The First Prize of Scholarship, Rank (4/38), Wenzhou University; </li>
                  </ul>
                  <ul>
		    <li>2023.10, National Scholarship (Top 2%), NJUST;</li>
                  </ul>
                  <ul>
                    <li>2022.10, Hua Wei Scholarship (Top 1%), NJUST;</li>
                  </ul>
                </td>
              </tr>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px">
                  <br>
                  <p style="text-align:center;font-size:small;">
                    This webpage is forked from <a href="https://github.com/fanjunkai1/fanjunkai1.github.io">Jon
                      Barron</a>. Thanks to him!
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
        </td>
      </tr>
  </table>
</body>

</html>
